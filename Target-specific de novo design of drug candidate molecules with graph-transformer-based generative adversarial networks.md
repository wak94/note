# Target-specific de novo design of drug candidate molecules with graph-transformer-based generative adversarial networks

# 摘要

发现新的候选药物分子是药物研发中的关键步骤。生成式深度学习模型能够从学习到的概率分布中采样生成新的分子结构；然而，这些模型在实际药物发现中的应用依赖于能够生成针对特定靶标分子的化合物。为此，我们提出了 **DrugGEN**，一个端到端的生成式系统，用于针对选定蛋白进行 **de novo** 药物候选分子设计。该方法将分子表示为图结构，并使用包含图变换器（graph transformer）层的生成对抗网络进行处理。DrugGEN 在大量类药物化合物以及靶标特异性生物活性分子数据集上训练后，为 AKT1（在多种癌症中起关键作用的激酶）设计了候选抑制剂。分子对接（docking）和分子动力学模拟表明，生成的化合物能够有效结合 AKT1，同时注意力图（attention maps）揭示了模型的推理逻辑。此外，经挑选的 **de novo** 分子经过合成，并在体外酶学实验中显示出对 AKT1 的低微摩尔（low micromolar）浓度抑制作用。这些结果展示了 DrugGEN 在设计靶向特异性分子方面的潜力。通过开放获取的 DrugGEN 代码库，研究者可以在已有生物活性分子数据集的基础上，将模型重新训练用于其他可药物化蛋白的设计。

# 背景

新药开发周期长且成本高，其中关键步骤是针对预定义靶标筛选生物活性化合物。尽管高通量筛选可同时检测数万种化合物，但化学空间与靶标空间庞大，最佳候选分子仍难以发现。现有小分子药物结构多样性低，仅能作用于特定蛋白家族，因此亟需真正新颖、结构多样的小分子，以靶向可药化蛋白及其临床相关变体。

“de novo 药物设计”旨在生成非已有结构的全新分子，但传统方法存在周期长、成本高及疗效安全未知等问题。近年来，AI 驱动的深度生成模型逐渐应用于此，通过条件训练、强化学习等方法优化分子设计，但仅优化性质不足以保证分子与靶标的有效结合。AI 驱动的靶向中心药物设计仍是新兴且潜力巨大的研究方向。

本研究提出 **DrugGEN**，一个端到端的小分子 **de novo 设计系统**，结合 GAN、transformer 和图表示学习生成靶向类药物分子。流程包括：构建小分子图数据集、训练与评估 DrugGEN 模型，以及分析筛选生成分子。以 AKT1 激酶为例，DrugGEN 成功生成候选抑制剂，展示了该方法在靶向特异性药物设计中的潜力。

# 方法

## 数据集

我们从不同数据源收集了两类数据用于训练 DrugGEN 深度生成模型：

1. **化合物数据**：包括药物及候选药物分子的原子组成、理化性质和结构特性，以及在生物靶点上的实验测定活性，代表“真实”样本。数据来源于 ChemBL (v.29) 开放数据库。根据重原子分布的中位数和标准差，我们设定单个分子最大重原子数为 45，最终确定数据集包含 **1,588,865 个小分子**。
2. **生物活性数据**：定量测量类药化合物与靶蛋白之间的物理相互作用，同样来自 ChemBL。通过标准化过滤（如单蛋白靶点、结合检测、有效 pChEMBL 值非空等），并筛选人类 AKT1（CHEMBL4282）靶蛋白的数据，保留 pChEMBL ≥ 6（即 IC₅₀ ≤ 1 μM）的配体，并加入 DrugBank 已知 AKT1 配体。剔除重原子数 >45 的分子后，最终得到 **2,607 个活性配体**用于训练 AKT1 生成模型。相同流程用于人类 CDK2（CHEMBL301），得到 **1,817 个化合物**。

该数据集包含分子结构与活性信息，可用于训练针对特定靶标的生成模型，重原子大小分布见下图：

<img src=".\Target-specific de novo design of drug candidate molecules with graph-transformer-based generative adversarial networks.assets\image-20251016205410337.png" alt="image-20251016205410337"  />

## 图编码（特征化）

在 DrugGEN 中，输入分子被表示为由两个组件组成的图：一个注释矩阵和一个邻接矩阵。注释矩阵编码原子特征，而邻接矩阵包含有关原子键存在性和类型的资讯。这些矩阵使用基于分子 SMILES 表示的 RDKit 库生成。原子数量和原子类型的选择旨在涵盖大多数真实抑制剂，并保持数据集中的计算效率。对于靶向 AKT1 的分子，注释矩阵维度为 $45 \times 9$，其中 $45$ 代表最大重原子数，$9$ 对应原子类型（C, N, O, F, P, S, Cl, I 和一个表示缺失原子的空标记）。相应的邻接矩阵尺寸为 $45 \times 45 \times 5$；此处第三维使用独热编码表示键类型（0 表示无键，1 表示单键，2 表示双键，3 表示三键，4 表示芳香键）。对于靶向 CDK2 的分子，注释矩阵维度为 $38 \times 10$，其中 $38$ 表示最大重原子数，$10$ 对应原子类型（C, N, O, F, P, S, Cl, Br, I 和一个空标记）。这些分子的邻接矩阵尺寸为 $38 \times 38 \times 5$，第三维同样如 AKT1 情况所述表示键类型。

## DrugGEN 架构

DrugGEN 模型基于 GAN 构建。图 2 展示了默认 DrugGEN 模型的整体工作流程。生成器 $G$ 是一个图变换器编码器，它将给定的输入 $z$ 转换为新的注释矩阵和邻接矩阵。然后，这些矩阵与真实小分子的矩阵一起输入判别器网络 $D$，以将其分配到“真实”和“伪造”组。各模块的详细信息如下所示。

<img src=".\Target-specific de novo design of drug candidate molecules with graph-transformer-based generative adversarial networks.assets\image-20251016210254118.png" alt="image-20251016210254118" style="zoom: 80%;" />

### 生成器

生成器（$G$）模块（图 2）使用 Transformer 编码器块，该模块操作于基于图的数据上——这是一种在分子数据分析中被证明非常有效的方法。为此，注释矩阵和邻接矩阵在同一模块中处理（有关注释矩阵和邻接矩阵的维度及上下文的详细信息，请参见“图编码（特征化）”部分）。与通常用作 GAN 生成器模块输入的随机噪声不同，$G$ 将从训练数据集中随机选取的真实类药分子作为输入。这种方法符合文献中的研究，即使用真实样本而非随机噪声作为 GAN 生成器的输入。此方法有助于模型有效地处理分子图的高度复杂性和稀疏性（即，对于靶向 AKT1 蛋白的分子，需 $45 \times 9 + 45 \times 45 \times 5 = 18,630$ 个元素来表示一个分子）。输入通过独立的多层感知机（MLP）分别处理注释矩阵和邻接矩阵，每层包含两层：输入层（9 维）、隐藏层（64 维）和输出层（128 维），以生成 AKT1 靶向分子的注释矩阵。这些 MLP 用于创建注释矩阵和邻接矩阵的嵌入，其维度为 $d_k$（默认值：128 维）。随后，输入被送入 Transformer 编码器模块。在经典的 Transformer 架构中，自注意力机制通过推导查询（QKV）、应用 softmax 函数，并最终乘以 $V$ 来计算。图 Transformer 通过将分子的邻接矩阵 $A_m$ 引入，将这一机制扩展到图结构数据，以考虑节点（原子）之间的连通性。在此设置下，$Q_m$、$K_m$ 和 $V_m$ 均由分子的注释矩阵推导得出。与原始 Transformer 不同，注意力权重是通过将缩放后的点积结果 $Q_m$ 和 $K_m$ 与 $A_m$ 相乘得到的。然后，所得的注意力再乘以 $V_m$，以创建注释矩阵的更新表示，而邻接矩阵的更新表示则是通过连接这些注意力权重形成的，如其他工作所述。执行注意力与邻接矩阵的逐元素相乘，目的是将键信息纳入其中，从而增强注意力得分。注意力矩阵旨在识别每个原子在成对方式下对其他原子的关注程度，这基于原子间短程（直接）和长程（间接）的关系/相互作用。因此，通过引入相应原子之间现成可用的键信息（即，是否存在原子键，若存在，则为何种特定类型的键），可以增强注意力值。在我们的模型中，我们从图 Transformer 的标准注意力公式开始。我们的关键修改是增加了一个额外的乘法步骤，涉及一个偏移的邻接矩阵（$A_m + 1$）。具体而言，我们首先将注意力乘以 $A_m$，然后再乘以 $(A_m + 1)$ 以放大边信号，从而增强模型捕捉细微结构特征的能力。最终注意力的计算公式如下：

$$
\text{Attention}(Q_m, K_m, V_m) = \text{softmax}\left(\frac{Q_m K_m^T}{\sqrt{d_k}} A_m (A_m + 1)\right) V_m
$$

其中，$Q_m$、$K_m$ 和 $V_m$ 表示分子的注释矩阵，而 $A_m$ 表示其邻接矩阵。$d_k$ 是 Transformer 编码器模块的维度，用于缩放注意力权重。在注意力层之后，最终的注释矩阵和邻接矩阵会经历一个聚合与归一化的过程。该变换包含两个主要步骤。首先，它们通过层归一化处理，确保每个矩阵的数值被适当缩放和中心化。层归一化的公式如下：

$$
\hat{X}^{l+1} = \text{LayerNorm}(X^l + \underline{X}^{l+1}), \quad \hat{A}^{l+1} = \text{LayerNorm}(A^l + \underline{A}^{l+1})
$$

其中，$X$ 和 $A$ 分别对应注释矩阵和邻接矩阵；$\text{LayerNorm}$ 表示层归一化，$l$ 是层数。$\hat{X}^{l+1}$ 表示层归一化后的中间产物。$X^l$ 是注意力机制前的注释矩阵，$\underline{X}^{l+1}$ 是注意力机制的产物。相同的符号也用于 $A$（邻接矩阵）。

接下来，这些矩阵通过一个前馈网络进一步处理，该网络引入非线性并从输入矩阵中学习复杂的高阶特征表示。该网络的输出随后被加回到先前归一化的矩阵上，形成残差连接。最终矩阵在末尾再次经过层归一化处理。第二个操作可表示为：

$$
X^{l+1} = \text{LayerNorm}(\hat{X}^{l+1} + \text{FFN}(\hat{X}^{l+1})), \quad A^{l+1} = \text{LayerNorm}(\hat{A}^{l+1} + \text{FFN}(\hat{A}^{l+1}))
$$

### 判别器

在生成对抗网络（GANs）中，判别器（$D$）的作用是比较由生成器生成的合成（伪造）数据 $G(z)$ 与真实分子数据 $x$，并将输入样本分类为“伪造”或“真实”。DrugGEN 的判别器（图 2）使用图 Transformer 编码器块构建，其功能与生成器类似。它首先通过节点层和边层的线性层处理注释矩阵和邻接矩阵，以获得嵌入表示。这些嵌入随后被送入 Transformer 编码器块（如生成器部分所述），以进一步转换表示。判别器配置为单个 Transformer 层，包含 8 个注意力头和 128 维的隐藏维度。在 Transformer 块之后，节点和边的表示被展平并拼接。最后，输出节点表示会经过一个预测头处理，该预测头由一个多层感知机（MLP）构成（输入：64；隐藏层1：32；隐藏层2：16；输出：1），以产生判别器的输出（即，用于真实/伪造评估的预测分数）。

## 基线模型

在消融研究中，我们实现了两种类型的基线模型，用于与 DrugGEN 进行对比。这两种模型均使用 WGAN 框架，但在其生成器和判别器模块的架构上有所不同。

第一种基线模型使用 MLP（多层感知机）模块。其设计改编自 MolGAN 生成器，并进行了修改，以便直接处理起始分子，而非基于噪声的输入。具体而言，基于 MLP 的生成器对展平后的注释矩阵和邻接矩阵应用两个全连接层（每层后跟一个修正线性单元激活函数）和一个 Dropout 层，最后通过一个读出层调整维度：

$$
X = \text{ReadOut}(\text{DropOut}(\text{ReLU}(\text{DenseLayer}(\text{ReLU}(\text{DenseLayer}(X)))))
$$

$$
A = \text{ReadOut}(\text{DropOut}(\text{ReLU}(\text{DenseLayer}(\text{ReLU}(\text{DenseLayer}(A)))))
$$

结果是，MolGAN 中原本用于将噪声映射到展平分子表示维度的初始全连接层被省略了。生成后，分子被输入到基于 MLP 的判别器中，该判别器首先将注释矩阵和邻接矩阵展平并拼接成一维向量。此判别器包含五个隐藏层（分别含 256、128、64、32 和 16 个神经元），后接一个单一输出神经元。我们训练了两种变体——MLP 基线（靶向）和 MLP-无靶标基线（非靶向）——并使用与 DrugGEN 相同的数据集和训练协议，以确保公平比较。

第二种基线模型将 DrugGEN 中的 Transformer 编码器块替换为 GCN（图卷积网络）层，应用于生成器和判别器中。对于生成器，三个连续的 GCN 层被应用于注释矩阵和邻接矩阵，以更新节点嵌入。这些嵌入随后通过一个最终的读出层重塑为生成分子的表示，以确保正确的输出维度。在判别器中，三个 GCN 层同样将输入分子（真实或生成的）编码为节点嵌入，然后将其聚合为一个单一特征向量。该向量被送入一个四层 MLP（输入大小为 64 个神经元，后接 32 和 16 个神经元的隐藏层，以及一个单一输出神经元），这与 DrugGEN 判别器相同，以产生最终的标量分数。

我们在与 DrugGEN 相同的训练、超参数和评估方案下开发了 MLP 和 GCN 基线模型（包括靶向和非靶向版本），以确保公平比较。这些基线模型获得的结果将在消融研究中进行讨论。

## 损失函数

DrugGEN 和基线模型均在模型训练中使用 WGAN 损失。DrugGEN 端到端训练的 WGAN 损失公式如下：

$$
L = (E_{x \approx p_r(x)}[D_1(x)] - E_{z \approx p_g(z)}[D_1(G_1(z))])
$$

其中，$x$ 表示真实分子，即已在判别器中使用的、经实验验证的目标抑制剂；$z$ 表示生成器的输入分布；$p_r$ 表示真实数据分布，$p_g$ 表示生成的数据分布。文献已表明，使用梯度惩罚可以提升 WGAN 的性能。因此，我们采用了梯度惩罚，其损失公式为：

$$
L_{GP} = \lambda E_{\hat{x} \approx p_{\hat{x}}(\hat{x})}[(\|\nabla_{\hat{x}} D(\hat{x})\|_2 - 1)^2]
$$

其中，$\lambda$ 表示惩罚系数，$\hat{x}$ 表示来自（1）$x$（真实数据）和（2）生成样本的数据。$p_{\hat{x}}(\hat{x})$ 表示从真实数据分布 $p_r$ 和生成器分布 $p_g$ 中的点对之间沿直线均匀采样的分布。我们通过结合公式 (6) 和 (7) 中给出的损失，得到了最终的损失函数：

$$
L_{Total} = L + L_{GP}
$$

## 训练方案、推理与超参数

DrugGEN 使用 ChemBL 化合物数据集进行训练（该数据集作为模型的真实分子输入）。ChemBL 数据集被随机划分为训练集和测试集，比例分别为 90% 和 10%。DrugGEN 首先用判别器 $D$ 开始训练（使用来自未训练生成器和真实样本的随机采样分子），随后再进展到生成器 $G$。我们使用 AdamW 优化器，并采用默认参数和 128 的批量大小。整个训练过程持续 100 个轮次；然而，我们基于有效性和新颖性指标提前停止了训练，主要目的是防止模式崩溃。

在超参数优化阶段，我们为每个模块独立测试了不同的学习率（$1 \times 10^{-5}, 5 \times 10^{-6}, 1 \times 10^{-7}, 0.0005, 0.0001, 0.005$ 和 $0.001$）。最终，所有模块（包括 $G$ 和 $D$）均选择了 $1 \times 10^{-5}$ 的学习率，这主要是为了获得模块稳定性。我们探索了不同注意力头数量（4、8 和 16）的影响，以评估其对模型性能的作用，结果支持使用 8 个注意力头，并且在所有模型中保持一致。我们评估了各种嵌入维度大小（16、32、64、128 和 256），以研究其对模型行为的影响。分析表明，128 的嵌入维度大小对于 DrugGEN 和 DrugGEN-NoTarget 模型均为最优。模型深度也经过了实验，我们探索了 1、2、4 和 8 的值，以理解其对性能的影响（结果见补充表 2）。我们观察到，更高的深度值会阻碍模型收敛。因此，主模型选择了 1 层 Transformer 深度。训练所报告的 DrugGEN 和 DrugGEN-NoTarget 模型各需约 2-3 天，使用单个 NVIDIA A5000 图形处理单元（24 GB 视频随机存取内存）。由于我们的基础设施存在较长的训练时长，上述所有分析均作为短期/快速测试进行。

在推理阶段，新生成的分子会经过修正以消除基于 SMILES 的错误，这一过程由 UnCorrupt SMILES 模型辅助完成。由于我们所使用的分子分析库（如 RDKit）的要求，在模型训练和验证的不同阶段，图与 SMILES 之间的正向和反向转换是必需的。

## 性能指标

模型的性能通过两组指标进行评估。第一组指标包含来自 MOSES 基准平台的四个基本分子生成指标：有效性（validity）、唯一性（uniqueness）、IntDiv 和新颖性（novelty）。这些指标用于评估模型的生成能力，通常关注从头生成分子的结构性质。

*   **有效性** 衡量生成分子在多大程度上符合定义化学合理性的特定规则和约束。其计算方式为：RDKit 的 SMILES 转换函数能够成功解析的数据所占的百分比。
*   **唯一性** 是衡量同一生成批次中是否存在冗余分子（即，彼此完全相同的分子）的指标。
*   **IntDiv**（内部多样性）是衡量一个特定生成批次内每对分子间平均成对不相似度的指标（基于使用扩展连接指纹计算的 Tanimoto 系数）。
*   **新颖性** 是指生成分子中未出现在用于训练的真实分子数据集中的分子比例。

本研究还引入了第二个与新颖性相关的指标——“相对于推理集的新颖性”（NI），用于消融研究中。NI 衡量的是在推理运行期间作为生成器模块输入的真实分子中，不存在的生成分子的比例。**有效性、唯一性、IntDiv、新颖性和 NI 的值越高，表明模型性能越好。**

第二组指标关注从头生成分子的“类药性”（drug-likeness）。其中最重要的两个指标是 QED 和 SA。
*   **QED**（定量估价药物相似性）利用分子描述符（如分子量、亲脂性、氢键供体和受体数量、极性表面积等）来计算分子的类药质量。
*   **SA**（合成可行性）分数通过将从头生成的分子与已标记的分子构建块进行比较，评估其合成难度。

**QED 值越高，SA 值越低，表明模型性能越好。**

除了上述指标外，我们还进一步使用 Lipinski 五规则、Veber 规则和 PAINS 过滤器来评估分子的类药性。
*   Lipinski 和 Veber 规则侧重于优化药物代谢动力学、生物利用度和膜通透性。
*   PAINS 过滤器则用于消除易产生非特异性结合或假阳性的化合物，以确保生物筛选的质量。

综合来看，这些规则和过滤器共同增强了对分子类药潜力的评估。我们还纳入了 Frechet ChemNet 距离指标，用于评估分子数据集间的物理化学相似性。该指标使用应用于由 ChemNet 模型生成的分子结构嵌入的 Frechet 距离。最后，为了评估结构相似性，我们使用了 MOSES 提供的 Murcko 骨架和片段相似性指标，以便进行对比分析。

## 分子对接

在对接研究中，所选靶蛋白 AKT1（PDB ID 4GVI）的晶体结构使用 Schrödinger Suite 2022-4 中的 Protein Preparation Wizard 和 OPLS4 力场进行准备。缺失的氢原子被添加，水分子被移除。pH 值设定为 $7.4 \pm 1.0$ 以进行原子类型划分。AKT1 的结合位点根据文献数据定义，包括 Ala177、Lys179、Lys182、Ala212、Glu228、Ala230、Glu234、Glu278、1hr291 和 Asp292。对接研究使用 Glide 进行，以确定每个配体的最佳得分结合构象。范德华半径缩放因子设置为 1.0，部分电荷截断值设置为 0.25。对接计算在标准精度模式下使用 GlideScore 评分函数进行。

相同的对接程序也应用于 CDK2（PDB ID 4KD1）。CDK2 的晶体结构以类似方式准备，其结合位点根据文献数据确认。所有结果均使用 PyMOL 进行可视化。

## 使用 UMAP 和 t-SNE 进行降维

图 3b 展示了从 DrugGEN、DrugGEN-NoTarget 模型（各 1,000 个）、真实 AKT1 抑制剂（模型训练中使用的所有分子）以及来自训练数据集的 50,000 个 ChemBL 分子中随机选取的一小部分从头生成分子的 UMAP（参数：n_neighbors = 50, min_dist = 0.8, metric = 'dice'）和 t-SNE（参数：perplexity = 500, iteration = 2,000）投影。在这些图中，每个点代表一个分子，颜色表示其来源，欧几里得距离大致指示基于 Tanimoto 系数（应用在分子指纹上，使用 Molecular Access System 描述符）的结构相似性。

## DEEPScreen 模型的训练与评估流程

真实分子和从头生成的分子均接受了针对选定蛋白（AKT1）的深度学习驱动的 D11 预测。我们为此目的使用了之前开发的 D11 预测系统——DEEPScreen。简而言之，DEEPScreen 使用二维（2D）图像形式的化合物结构 Kekulé 表示（$300 \times 300$ 像素），这些图像由 RDKit 的 Draw.MolToImageFile 函数创建，并通过深度卷积神经网络对其进行处理，以分类它们对目标蛋白是“活性”还是“非活性”。我们选择 DEEPScreen 进行本分析，原因有三：(1) 准备输入数据并训练/测试一个特定靶点的 D11 预测模型非常直接；(2) 它仅需要生物活性数据；(3) 它具有很高的预测性能。DEEPScreen 在建模方法、数据集和输出方面完全独立于 DrugGEN。因此，这种基于 D11 预测的验证是客观的。

为此，我们首先使用 ChemBL (v. 35) 中可用的实验生物活性数据，为 AKT1 蛋白训练了一个 DEEPScreen 模型。训练数据包含 1,932 个活性小分子和 2,414 个非活性小分子（活性阈值选择为 pChEMBL 值 = 6，相当于 $IC_{50}$ 为 $1\,\mu M$ 的浓度）。

我们将化合物数据集使用 chemprop 库中的平衡支架分割函数划分为训练集、验证集和测试集。通过确保各分组间的标签比例均衡，数据集被划分为包含 3,090、774 和 968 个分子的训练集、验证集和测试集。我们通过对每个活性和非活性分子进行 $10^\circ$ 旋转（图像围绕中心点旋转）来增强数据集，使每个输入样本共生成 36 张图像。这样做是为了使模型具备旋转不变性。其他类型的图像变换（如平移）在此情况下无关紧要，因为 RDKit 的 2D 图像生成函数会标准化分子绘图。我们使用 0.5 的置信度分数阈值对模型进行评估（用于二元分类任务：活性/非活性），将分数 ≥ 0.5 的分子分类为活性，这对应于 ≥ 18 张增强图像。我们针对验证集上的分类指标优化了模型的超参数，并在独立的保留测试集上测量了最终性能。

随后，使用与 RDKit Draw.MolToImageFile 相同的参数，生成了真实分子和从头生成分子的 2D 结构图像。这些图像在已训练好的 AKT1 模型的预测/推理模式下运行。有关 DEEPScreen 系统及其训练的详细信息，请参见 https://github.com/HUBioDataLab/DEEPScreen2。

